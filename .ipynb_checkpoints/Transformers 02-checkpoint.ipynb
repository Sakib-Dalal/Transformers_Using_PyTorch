{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e5a4e7-80e7-4c89-b2b1-ae40d2e078b1",
   "metadata": {},
   "source": [
    "# Building Transformers using Pytorch Transformers Method\n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20250325174552667398/transformer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c620685e-e515-4305-97a9-85fb5dd721cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f98176-5a50-469b-8be1-b0a040f55828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f599b1-af9c-4714-be84-851eb9fd4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformers(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size, \n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        max_len=100\n",
    "    ):\n",
    "        super(SimpleTransformers, self).__init__()\n",
    "\n",
    "        self.src_embedding = nn.Embedding(num_embeddings=src_vocab_size, embedding_dim=d_model)\n",
    "        self.tgt_embedding = nn.Embedding(num_embeddings=tgt_vocab_size, embedding_dim=d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Pytorch Transformer\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_emb = self.pos_encoder(self.src_embedding(src))\n",
    "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt))\n",
    "\n",
    "        output = self.transformer(src_emb, tgt_emb)\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2fc948c-096b-4ae2-9b40-fc243a437173",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 15, 10000])\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = 10000\n",
    "tgt_vocab_size = 10000\n",
    "\n",
    "model = SimpleTransformers(src_vocab_size, tgt_vocab_size)\n",
    "\n",
    "src = torch.randint(0, src_vocab_size, (32, 20))  # batch=32, seq_len=20\n",
    "tgt = torch.randint(0, tgt_vocab_size, (32, 15))\n",
    "\n",
    "output = model(src, tgt)\n",
    "print(output.shape)  # (32, 15, tgt_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b7c61e-9b8b-47f9-8c71-7697c2d86d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1232,  0.1974,  0.2311,  ...,  0.7546, -0.0971, -0.5343],\n",
       "         [-0.5452, -0.2743,  0.5020,  ...,  0.5108, -0.3281, -0.2989],\n",
       "         [-0.2360, -0.0759, -0.0610,  ..., -0.1975, -0.1219, -0.7713],\n",
       "         ...,\n",
       "         [-0.6507, -0.0919,  0.0209,  ...,  0.1554,  0.0329,  0.0339],\n",
       "         [-0.3224,  0.2080, -0.1527,  ...,  0.5321,  0.4047, -0.5693],\n",
       "         [-0.9821, -0.3305,  0.4270,  ...,  0.2308, -0.1707, -0.6261]],\n",
       "\n",
       "        [[-0.6786,  0.2414,  0.4896,  ...,  0.2271,  0.1008, -0.9225],\n",
       "         [ 0.0511,  0.2614,  0.8016,  ...,  0.1394,  0.0407, -0.8343],\n",
       "         [-0.4496,  0.0155,  0.4898,  ...,  0.7178,  0.4297, -0.5523],\n",
       "         ...,\n",
       "         [-0.4567,  0.4619, -0.2568,  ...,  0.6354,  0.4413, -0.7411],\n",
       "         [-0.3466,  0.3697, -0.1801,  ...,  0.3141,  0.3780, -1.1125],\n",
       "         [-0.1956,  0.7709, -0.0984,  ...,  1.0252,  0.2743, -0.3762]],\n",
       "\n",
       "        [[-0.1776,  0.3541,  0.4787,  ...,  0.2038, -0.0803, -0.4546],\n",
       "         [-0.0384,  0.4412, -0.3236,  ...,  0.3679,  0.0889, -0.4369],\n",
       "         [ 0.3137,  0.2187, -0.0260,  ...,  0.1351, -0.4098, -0.6884],\n",
       "         ...,\n",
       "         [-0.0187,  0.1153, -0.2050,  ...,  0.3351, -0.1788,  0.0462],\n",
       "         [-0.0873,  0.1766,  0.1539,  ...,  0.4816, -0.1084, -0.3975],\n",
       "         [-0.0402,  0.0996, -0.5037,  ..., -0.1866, -0.0515,  0.0222]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0740,  0.5493, -0.4737,  ...,  0.2609,  0.2989, -0.0198],\n",
       "         [-0.5247,  0.2762,  0.1511,  ..., -0.3170,  0.1295, -0.3746],\n",
       "         [ 0.0170, -0.0747,  0.0101,  ..., -0.0034, -0.0154, -0.3832],\n",
       "         ...,\n",
       "         [-0.3667,  0.6871, -0.0660,  ...,  0.1448,  0.7853, -0.3041],\n",
       "         [-0.1832,  0.4390, -0.2881,  ..., -0.0189,  0.2853, -0.2916],\n",
       "         [-0.2812,  0.0934, -0.1269,  ...,  0.3973, -0.3504, -0.3845]],\n",
       "\n",
       "        [[ 0.4333, -0.2997, -0.5501,  ...,  0.0836,  0.5382, -0.0564],\n",
       "         [ 0.0796, -0.1395, -0.4194,  ..., -0.0974,  0.1706, -0.4564],\n",
       "         [ 0.2126, -0.4317,  0.2120,  ..., -0.6852,  0.1610, -0.5669],\n",
       "         ...,\n",
       "         [ 0.1160,  0.7364, -0.1575,  ...,  0.3241,  0.4623, -0.6905],\n",
       "         [ 0.7184,  0.2391, -0.3193,  ...,  0.0055,  0.4502, -0.4979],\n",
       "         [ 0.2458, -0.0649,  0.4145,  ...,  0.1182, -0.1019, -0.7845]],\n",
       "\n",
       "        [[-0.1899,  0.5255,  0.1328,  ...,  0.2572,  0.9883, -1.2669],\n",
       "         [-0.2405, -0.0504, -0.0174,  ...,  0.1501, -0.0332, -0.9491],\n",
       "         [-0.3199,  0.2653, -0.4955,  ...,  0.5084,  0.2213, -0.9227],\n",
       "         ...,\n",
       "         [ 0.1541,  0.3948, -0.3054,  ..., -0.0767,  0.3037, -0.9066],\n",
       "         [-0.3635,  0.1894, -0.0485,  ..., -0.2690,  0.9758, -0.5916],\n",
       "         [ 0.4093,  0.5007,  0.1923,  ...,  0.9091,  0.7112, -0.6848]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5431c-ed91-4317-9295-23bc5fdfd96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (CloudLab)",
   "language": "python",
   "name": "cloudlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
