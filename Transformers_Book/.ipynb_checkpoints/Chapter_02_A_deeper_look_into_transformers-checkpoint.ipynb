{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15841f2c-d7f2-4b5b-b970-86f064c2f0d3",
   "metadata": {},
   "source": [
    "# Chapter_02: A Deeper look into transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19e19fb-8b13-424b-86fa-36939e49f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650b16d1-9290-4cfd-a7b1-6ff9d9e3c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da26347-272d-45c4-bced-005004915fd1",
   "metadata": {},
   "source": [
    "## Encoder and decoder stacks\n",
    "\n",
    "## Encoder Part of the Transformer\n",
    "\n",
    "### Simplified encoder layer example\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F334288604%2Ffigure%2Ffig1%2FAS%3A778232232148992%401562556431066%2FThe-Transformer-encoder-structure.ppm&f=1&nofb=1&ipt=41cff290b603e54651f280652c0c36716a4db949384a706382450d2c4de21547\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22e83f77-2a93-4f9d-b5e3-ab9f8bdda9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1, mask=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Self Attention Layer\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, dropout=dropout, device=DEVICE, batch_first=True)\n",
    "\n",
    "        # FFN Layer\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, 2 * dim_feedforward),\n",
    "            nn.GLU(dim=-1), # shape: dim_feedforward\n",
    "            nn.Linear(in_features=dim_feedforward, out_features=d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # Normalization Layers\n",
    "        self.norm1 = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.norm2 = nn.LayerNorm(normalized_shape=d_model)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Self Attention Layer\n",
    "        attn_output, attn_output_weights = self.self_attn(query=x, key=x, value=x, attn_mask=mask)\n",
    "        \n",
    "        x = x + self.dropout1(attn_output) # -------> Residual connection\n",
    "        x = self.norm1(x) # ---------> Normalisation\n",
    "\n",
    "        # FFN Layer\n",
    "        ff_output = self.feed_forward(x)\n",
    "        \n",
    "        x = x + self.dropout2(ff_output) # -------> Residual connection\n",
    "        x = self.norm2(x) # ---------> Normalisation\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2ba22dc-a3b0-4a33-a312-9bc6281751de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "d_model = 512\n",
    "nhead = 1\n",
    "dim_feedforward = 1024\n",
    "mask = None\n",
    "dropout=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f9c0178-aedc-48f2-bce3-452a180b33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, mask=mask).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e764ee75-72b6-4d8b-b29b-62b4499d63d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (feed_forward): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (1): GLU(dim=-1)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdf93d-e0ee-45ae-8f56-9cf2e5e2142f",
   "metadata": {},
   "source": [
    "- 1 sentence\n",
    "- 10 tokens\n",
    "- each token â†’ 512-d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb7eeb48-47b5-407a-a707-e44078252006",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(1, 10, 512).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74af5da9-4e65-4dbc-8104-fac2aa37ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder(X).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d08b2c2-4025-4702-b06e-9e54e993bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ec313a7-1084-49b5-8c73-5a5a897cec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0316, -1.2937, -0.6671,  ...,  0.3537,  0.4786, -0.1570],\n",
       "         [ 0.2058, -0.9301, -0.1024,  ..., -0.2799,  0.5939, -0.1482],\n",
       "         [-0.9173,  1.0031,  1.0584,  ...,  1.5927, -0.3666,  0.7721],\n",
       "         ...,\n",
       "         [-0.5479, -1.6185,  0.2500,  ..., -0.2237, -0.4919,  1.0004],\n",
       "         [ 0.3741, -1.0538, -1.5171,  ..., -0.3846,  0.1506, -0.6575],\n",
       "         [-0.7019, -0.4913, -0.5312,  ...,  0.7327,  0.3981,  0.9056]]],\n",
       "       device='mps:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4df54e02-ac55-49b4-af5f-8b6a5e3d3e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9320, -1.2575, -0.8526,  ...,  0.1295,  0.3823, -0.1893],\n",
       "         [ 0.2127, -0.9730, -0.3256,  ...,  0.1059,  0.4513,  0.1268],\n",
       "         [-0.8601,  1.3270,  0.7551,  ...,  1.6539, -0.4757,  0.8001],\n",
       "         ...,\n",
       "         [-0.9603, -1.3108,  0.0224,  ...,  0.0707, -0.3812,  1.0555],\n",
       "         [ 0.4042, -0.4574, -1.9427,  ..., -0.0130,  0.3644, -0.3996],\n",
       "         [-0.6386, -0.4629, -0.4960,  ...,  1.1980,  0.4254,  1.0251]]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35ab9c-d17d-41a3-b7b6-ea85a73fb845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (CloudLab)",
   "language": "python",
   "name": "cloudlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
